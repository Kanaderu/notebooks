{
 "metadata": {
  "name": "",
  "signature": "sha256:3e81e93e5dc9469cd71453fb621cbc06683f1908f6bd720910705ed9cdafbe8c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Notebook description"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook describes the connection algorithm used by the Builder. \n",
      "\n",
      "The Builder takes a nengo Network containing Ensembles, Nodes, and Connections and converts it into NGPy Pools, StateSpaces, and WeightedProjections. The Builder must implement the functionality described by the nengo Network but has many degrees of freedom in its actual implementation. Specifically, the Builder implements Connections as WeightedProjections among StateSpaces and Pools. So long as the network structure of these projections effectively implement the nengo Network connectivity, the Builder designer is free to arrange them as seen fit.\n",
      "\n",
      "On hardware, the connection matrix of a WeightedProjection is stored in memory and thus has an associated cost in terms of memory. The Builder designer's goal is to implement the nengo Network's connectivity for the minimum cost in terms of memory used. This notebook will discuss several approaches to implementing network connectivity, which can be divided into per-connection and multi-connection methods:\n",
      "\n",
      "Per-connection methods:\n",
      " - direct translation\n",
      " - decode-transform-encode factorization\n",
      " - transform folding\n",
      " \n",
      "Multi-connection methods:\n",
      " - decode matrix sharing\n",
      " - encoding matrix sharing"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Terminology"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An Ensemble has $N$ neurons and encodes $e$-dimesions with its $N\\times e$ encode matrix, $\\boldsymbol{e}$. \n",
      "\n",
      "Each connection out of an Ensemble specifies a $d$-dimensional function. The function is approximated using a $d\\times N$ decode matrix, $\\boldsymbol{d}$. Optionally, a connection can also specify a transform matrix, $\\boldsymbol{M}$. The transform matrix is applied after the decode matrix and is $e'\\times d$, where $e'$ is the dimensionality of the connection target. Usually, $e'$ is the encoding dimensionality of another Ensemble. If a transformation matrix is not supplied, it is assumed to be the identity matrix\n",
      "\n",
      "A general rule of thumb in constructing networks is that $d\\approx e$ and $N\\approx 50e$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![nengo objects](figs/nengo_objects.png \"nengo objects\")\n",
      "\n",
      "represent nengo objects, and \n",
      "\n",
      "![NGPy objects](figs/NGPy_objects.png \"NGPy objects\")\n",
      "\n",
      "represent NGPy objects"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Per-connection methods"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These methods only consider connections individually in their implementation. They are simple to implement but far from optimal. Consider this simple network connecting two Ensembles:\n",
      "\n",
      "![A connects to B](figs/simple_nengo_network.png \"simple network\")"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "direct translation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The simplest way to implement a Connection is as a single WeightedProjection that lumps together the decode, transformation, and encode matrices.\n",
      "\n",
      "![pool to pool](figs/pool_pool.png \"pool to pool\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This WeightedProjection requires $N^2$ memory per connection because\n",
      "\n",
      "$$\\overbrace{\\boldsymbol{d}}^{N\\times d}\\times \\overbrace{\\boldsymbol{M}}^{d\\times e}\\times \\overbrace{\\boldsymbol{e}}^{e\\times N}$$\n",
      "\n",
      "produces an $N\\times N$ matrix. $N^2$ is very big number, so we always avoid this method."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "decode-transform-encode factorization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next best connection scheme implements the Connection as three weighted projections: one for each transformation matrix.\n",
      "\n",
      "![Connection as three weighted projections](figs/pool_ss_ss_pool.png \"Connection as three weighted projections\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As three separate matrices per connection, this method requires \n",
      "\n",
      "$$(d\\times N) + (e\\times d) + (N\\times e)$$ \n",
      "\n",
      "memory per connection. Using the rule of thumb assumptions that $d=e$ and $N=50e$, this would cost\n",
      "\n",
      "$$\\left(\\frac{N}{50}\\times N\\right) + \\left(\\frac{N}{50}\\times \\frac{N}{50}\\right) + \\left(N\\times \\frac{N}{50}\\right) \n",
      "\\approx \\frac{N^2}{25}$$\n",
      "\n",
      "memory per connection, which is certainly better than direct translation."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "transform folding"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A slight improvement on completely factorizing the decode, transform, and encode matrices is to fold the transform matrix into the decode matrix or into the encode matrix. Whether to fold the transform matrix into the decode matrix or the encode matrix depends on the relative sizes of $d$ and $e$. In any case, folding the transform matrix eliminates the cost of storing the transform matrix.\n",
      "\n",
      " - If $d>e$, then it's better to fold the transform matrix into the decode matrix.\n",
      " - If $d<e$, then it's better to fold the transform matrix into the encode matrix.\n",
      " - If $d=e$, then it doesn't matter which matrix we fold the transform into.\n",
      "\n",
      "![Transform folded into decode matrix](figs/pool_sse_pool.png \"Transform folded into decode matrix\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Folding the transform matrix into the decode matrix requires\n",
      "\n",
      "$$\n",
      "(e\\times d)(d\\times N) + (N\\times e) = (e\\times N) + (N\\times e)\n",
      "$$\n",
      "\n",
      "memory per connection."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Multi-connection methods"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The multi-connection methods of decode/encode matrix sharing save memory by reducing redundancy in a Network's connectivity. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "decode sharing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Often, Ensembles will have multiple output connections transmitting the same function or linear transforms of the same function. Say a function $f(x)$ is decoded out of Ensemble $A$ and sent to Ensembles $B0,B1,B2$ with linear transforms $M_0,M_1,M_2$ respectively.\n",
      "\n",
      "![Ensemble fanout](figs/ensemble_fanout.png \"Ensemble fanout\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using just the decode-transform-encode factorization, we create a network with redundante decode StateSpaces:\n",
      "\n",
      "![Pool-Statespace-Statespace-Pool fanout](figs/pool_fanout.png \"Pool-Statespace-Statespace-Pool fanout\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, the first layer of connections decodes the target function $f(x)$, the second layer of connections implements the linear transforms $M_i$, and the third layer of connections encodes the transformed functions. For an Ensemble fanning out with $k$ connections, this costs\n",
      "$$k\\left((d\\times N) + (e\\times d) + (N\\times e) \\right).$$\n",
      "\n",
      "All of the StateSpaces (SS_Ai) targeted by the first layer of connections represent the same decoded function, so we can eliminate the redundancy by sharing a single decode StateSpace across connections.\n",
      "\n",
      "![Fanout shares decoders](figs/pool_fanout_shared_decode.png \"Fanout shares decoders\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The memory cost after eliminating the redundant StateSpaces is \n",
      "\n",
      "$$\n",
      "(d\\times N)+k\\left((e\\times d) + (N\\times e) \\right),\n",
      "$$\n",
      "\n",
      "which has a savings of $(k-1)(d\\times N)$ over using decode-transform-encode factorization alone. \n",
      "\n",
      "**Caveats:**\n",
      "\n",
      " - Decode StateSpaces can only be shared by Connections that use linear transforms of the same function.\n",
      " - Sharing of a decode StateSpace restricts when the transform matrix can be folded into the decode matrix. Sometimes it is cheaper to not share a decode StateSpace and instead fold the transformation matrices into the decode matrices.\n",
      "\n",
      "\n",
      "*Multiple connections with multiple functions:*\n",
      "\n",
      "If an ensemble has multiple output connections with different functions, it must use a different decode matrix for each function. \n",
      "\n",
      "![Ensemble fans out with two functions](figs/ensemble_fanout_2fun.png \"Ensemble fans out with two functions\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we decode both $f(x)$ and $g(x)$ out of Ensemble A. Therefore we need at least two different decode StateSpaces, one for each function.\n",
      "\n",
      "![PSSP fans out for two functions](figs/pool_fanout_2fun.png \"PSSP fans out for two functions\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "SS_A0 represents the decode of $f(x)$ while SS_A1 represents the decode of $g(x)$.\n",
      "\n",
      "*Sharing decodes restricts transform folding, and is not always optimal:*\n",
      "\n",
      "When sharing the decode StateSpace, we cannot, in general, fold the transform matrix into the decode matrix because it is shared across multiple connections. The exception is if the connections all have the same transform matrix.\n",
      "\n",
      "Sharing the decode matrix can actually be more costly than having redundant decode StateSpaces and folding the transform matrices into the decode matrices. The comparison is $(d\\times N)+k(e\\times d)+k(N\\times e)$ for decode sharing versus $k(e\\times N) + k(N\\times e)$ for transform folding. However, when $e=d$ and $N>d$, decode sharing is usually the way to go."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "encode sharing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As Ensembles may have multiple output connections so Ensembles may have multiple input conections:\n",
      "\n",
      "![Ensemble fanin](figs/ensemble_fanin.png \"Ensemble fanin\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With multiple input connections, if we only use the decode-transform-encode factorization, we create a network with redundant encode StateSpaces:\n",
      "\n",
      "![PSSP fanin](figs/pool_fanin.png \"PSSP fanin\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, StateSpaces SS_B0, SS_B1, and SS_B2 all deliver their encoded values via the same encoding matrix of Pool_B, which sums their contributions. For an ensemble with $k$ input connections, the cost of this approach is\n",
      "\n",
      "$$k\\left((d\\times N) + (e\\times d) + (N\\times e) \\right).$$\n",
      "\n",
      "We can eliminate the redundant encoding matrices by sharing the encoding StateSpace. \n",
      "\n",
      "![Shared encoder fanin](figs/pool_fanin_shared_encode.png \"Shared encoder fanin\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, the contributions from the A layer are summed in StateSpace SS_B before being delivered to Pool_B. This approach then costs\n",
      "\n",
      "$$k\\left((d\\times N) + (e\\times d)\\right) + (N\\times e),$$\n",
      "\n",
      "Which has a savings of $(k-1)(N\\times e)$ over using the decode-transform-encode factorization alone.\n",
      "\n",
      "**caveat**\n",
      "\n",
      "Sharing of an encode StateSpace restricts when the transform matrix can be folded into the encode matrix. Sometimes it is cheaper to not share an encode StateSpace and instead fold the transformation matrices into the encode matrices. The comparison is $k(d\u00d7N)+k(e\u00d7d)+(N\u00d7e)$ for encode sharing versus $k(d\u00d7N)+k(N\u00d7d)$ for transform folding. However, when $e=d$ and $N>e$, encode sharing is usually the way to go.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}