{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Description\n",
    "\n",
    "If we don't konw the underlying dynamics of a system, we'll have to either fit or \"learn\" the dynamics.\n",
    "\n",
    "In this notebook, we'll explore techniques for fitting and learning dynamics.\n",
    "\n",
    "A dynamical system given by\n",
    "\n",
    "$$\\dot{x}=f(x) + g(u)$$\n",
    " \n",
    "but with synapses, ensembles implement\n",
    "\n",
    "$$\\tau_{syn}\\dot{x}=-x+f'(x)+g'(u)$$\n",
    "\n",
    "to make the network implement the desired $f(x)$ and $g(u)$, we decode $f'(x)$ and feed in $g'(u)$\n",
    "\n",
    "\\begin{align}\n",
    "f'(x) &= \\tau_{syn} f(x) + x \\\\\n",
    "g'(u) &= \\tau_{syn} g(u)\n",
    "\\end{align}\n",
    "\n",
    "## Workflow\n",
    " - Generate dynamical system\n",
    " - Fit dynamics to basis functions\n",
    " - Approximate dynamical system with nengo\n",
    " - Load in real accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "import nengo\n",
    "from nengo.utils.ensemble import tuning_curves\n",
    "from nengo.utils.functions import piecewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     18,
     24
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class DSProcessor:\n",
    "    \"\"\"Dynamical Systems Processor\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dim: int\n",
    "        dimensions\n",
    "    nrns: int\n",
    "        number of neurons\n",
    "    dt: float\n",
    "        simulator timestep\n",
    "    fb_fn: function or (state, dstate) tuple\n",
    "        closed form function or input/output data pairing\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, nrns, dt, fb_fn,\n",
    "                 in_fn=None, radius=1, tau=0.1, seed=0,\n",
    "                 neuron_type=nengo.LIFRate(), max_rates=nengo.dists.Uniform(200, 400)):\n",
    "        self.dt = dt\n",
    "        if callable(fb_fn):\n",
    "            def function(x):\n",
    "                dx = fb_fn(x)\n",
    "                ret = [tau*dx_val + x_val for dx_val, x_val in zip(dx, x)]\n",
    "                return ret\n",
    "            eval_points = None\n",
    "        else:\n",
    "            state, dstate = fb_fn\n",
    "            function = tau*dstate + state\n",
    "            eval_points = state\n",
    "            \n",
    "        self.net = nengo.Network(seed=seed)\n",
    "        with self.net:\n",
    "            ens = nengo.Ensemble(\n",
    "                nrns, dim, neuron_type=neuron_type,\n",
    "                radius=radius, seed=seed, max_rates=max_rates)\n",
    "            readout = nengo.Node(None, size_in=dim)\n",
    "            self.probe = nengo.Probe(readout, synapse=None)\n",
    "            \n",
    "            self.conn = nengo.Connection(ens, ens, function=function, eval_points=eval_points, synapse=tau)\n",
    "            nengo.Connection(ens, readout, function=function, eval_points=eval_points, synapse=tau)\n",
    "            if in_fn is not None:\n",
    "                stim = nengo.Node(in_fn)\n",
    "                nengo.Connection(stim, ens, transform=tau, synapse=tau)\n",
    "                nengo.Connection(stim, readout, transform=tau, synapse=tau)\n",
    "                self.stim_probe = nengo.Probe(stim, synapse=None)\n",
    "            else:\n",
    "                self.stim_probe = None\n",
    "        self.ens = ens\n",
    "        self.sim = nengo.Simulator(self.net, dt)\n",
    "\n",
    "    def run(self, sim_time):\n",
    "        self.sim.run(sim_time)\n",
    "        state = self.sim.data[self.probe]\n",
    "        dstate_dt = np.diff(state, axis=0) / dt\n",
    "        return self.sim.trange()[:-1], state[:-1], dstate_dt\n",
    "    \n",
    "    def get_target_decode(self, dstate_dt):\n",
    "        \"\"\"Compute the target decode points that an Ensemble's decoders should be optimized for\n",
    "        \n",
    "        Run simulator first\n",
    "        \"\"\"\n",
    "        if self.stim_probe:\n",
    "            fb_tgts = dstate_dt - self.sim.data[self.stim_probe][:-1]\n",
    "        else:\n",
    "            fb_tgts = dstate_dt\n",
    "        return fb_tgts\n",
    "\n",
    "    def get_fit(self, test_inputs):\n",
    "        test_inputs, activities = tuning_curves(self.ens, self.sim, test_inputs)\n",
    "        decoded_values = np.dot(activities, self.sim.data[self.conn].weights.T)\n",
    "        return decoded_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll test our paradigm with a 1D low-pass filter.\n",
    "\n",
    "Desired dynamics are given by\n",
    "$$\\dot{x} = \\frac{-1}{\\tau_{sys}}x + \\frac{1}{\\tau_{sys}}u$$\n",
    "\n",
    "Therefore we train our ensemble to decode and feed back\n",
    "\n",
    "$$\\tau_{syn}\\left(\\frac{-1}{\\tau_{sys}}x\\right)+x=\\left(1-\\frac{\\tau_{syn}}{\\tau_{sys}}\\right)x$$\n",
    "\n",
    "When $\\tau_{syn}>\\tau_{sys}$, we're training for negative feedback, and when $\\tau_{syn}<\\tau_{sys}$, we're training for positive feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_1d_lds():\n",
    "    sys_tau = 0.2\n",
    "    sim_time = 5*sys_tau\n",
    "    dt = 0.001\n",
    "\n",
    "    test_state = np.linspace(-1, 1.0).reshape((-1, 1)) # for comparing decodes\n",
    "\n",
    "    def fb_fn(x):\n",
    "        return [-x/sys_tau]\n",
    "    def in_fn(t):\n",
    "        return [1/sys_tau]\n",
    "    dsp_ref = DSProcessor(1, 100, dt, fb_fn, in_fn=in_fn)\n",
    "    time, state, dstate = dsp_ref.run(sim_time)\n",
    "    ref_decode = dsp_ref.get_fit(test_state)\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "    axs[0].plot(time, state, label=\"reference\")\n",
    "    axs[1].plot(state, dstate, label=\"reference\")\n",
    "    axs[2].plot(test_state, ref_decode, label=\"reference\")\n",
    "\n",
    "    tgt_dstate = dsp_ref.get_target_decode(dstate)\n",
    "    dsp_appx = DSProcessor(1, 64, dt, (state, tgt_dstate), in_fn=in_fn)\n",
    "    time, state_appx, dstate_appx = dsp_appx.run(sim_time)\n",
    "    axs[0].plot(time, state_appx, label=\"fit\")\n",
    "    axs[1].plot(state_appx, dstate_appx, label=\"fit\")\n",
    "    decode_appx = dsp_appx.get_fit(test_state)\n",
    "    axs[2].plot(test_state, decode_appx, label=\"fit\")\n",
    "    \n",
    "    axs[0].legend(loc=\"best\")\n",
    "    axs[0].set_xlabel(\"time\")\n",
    "    axs[0].set_ylabel(\"state\")\n",
    "    axs[1].legend(loc=\"best\")\n",
    "    axs[1].set_xlabel(\"state\")\n",
    "    axs[1].set_ylabel(\"observed dstate/dt\")\n",
    "    axs[2].legend(loc=\"best\")\n",
    "    axs[2].set_xlabel(\"state\")\n",
    "    axs[2].set_ylabel(\"feedback decode\")\n",
    "    plt.tight_layout()\n",
    "test_1d_lds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed reference system data was used for fitting. Fit and reference state and dstate/dt look reasonable. Note how the fit feedback decode only well-approximates the reference decode over the state range used as inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO next\n",
    "\n",
    "cleanup van der pol oscillator\n",
    " - use new DSProcessor\n",
    " - plot fit over x, y space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a 2D nonlinear, non-chaotic, [Van der Pol oscillator](https://en.wikipedia.org/wiki/Van_der_Pol_oscillator), oscillator dyanmical system\n",
    "\n",
    "\\begin{align*}\n",
    "\\dot{x} &= y \\\\\n",
    "\\dot{y} &= \\mu(1-x^2)y-x \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Use these in your simulation\n",
    "dt = 0.001\n",
    "sim_time = 20.  # duration of simulation\n",
    "\n",
    "input_fn = piecewise({0.:[1., 0.], 1.:[0., 0.]})  # Use this as the input function to your network\n",
    "mu = 1.  # damping coefficient\n",
    "def vanderpol(x, mu=1.):\n",
    "    ret = np.array([x[1], mu*(1.-x[0]**2)*x[1]-x[0]])\n",
    "    return ret\n",
    "dsp = DSProcessor(vanderpol, input_fn=input_fn, dim=2, radius=1, neuron_type=nengo.Direct())\n",
    "ref_time, ref_state, ref_dstate = dsp.generate_data(sim_time, dt=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# figure out what to use for training\n",
    "t_clip = 5\n",
    "t_idx = np.searchsorted(ref_time, t_clip)\n",
    "\n",
    "plt.plot(ref_time, ref_state)\n",
    "plt.plot(ref_time[t_idx:], ref_state[t_idx:])\n",
    "plt.xlabel(r'$t$')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ref_state[:, 0], ref_state[:, 1])\n",
    "plt.plot(*ref_state[t_idx:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(ref_time, ref_state[:, 0], label=r\"$x$\")\n",
    "plt.plot(ref_time, ref_state[:, 1], label=r\"$y$\")\n",
    "plt.xlabel('Time', fontsize=14)\n",
    "plt.ylabel(\" \", fontsize=16)\n",
    "plt.legend(loc=\"best\", fontsize=16)\n",
    "plt.xlim((0, np.max(ref_time)))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(*ref_state.T, color=\"#2ca02c\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.xlabel(r'$x$', fontsize=16)\n",
    "plt.ylabel(r'$y$', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_vdp(ref_time, ref_state, appx_time, appx_state):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    c0 = plt.plot(ref_time, ref_state[:, 0], '--', alpha=0.3)[0].get_color()\n",
    "    c1 = plt.plot(ref_time, ref_state[:, 1], '--', alpha=0.3)[0].get_color()\n",
    "    plt.plot(appx_time, appx_state[:, 0], color=c0)\n",
    "    plt.plot(appx_time, appx_state[:, 1], color=c1)\n",
    "    plt.xlabel('Time', fontsize=14)\n",
    "    plt.ylabel(\" \", fontsize=16)\n",
    "    plt.xlim((0, np.max(ref_time)))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(*ref_state.T, '--', color=\"#2ca02c\", alpha=0.3)\n",
    "    plt.plot(*appx_state.T, color=\"#2ca02c\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(r'$x$', fontsize=16)\n",
    "    plt.ylabel(r'$y$', fontsize=16)\n",
    "    \n",
    "for npd in [16, 32, 64]: #[16, 32, 64, 128, 256, 512]:\n",
    "    appx_time, appx_state = approximate_ds(2, npd, ref_state[t_idx:], ref_dstate[t_idx:], sim_time,\n",
    "                                           radius=1, dt=dt, input_fn=input_fn, neuron_type=nengo.LIF())\n",
    "    plot_vdp(ref_time, ref_state, appx_time, appx_state)\n",
    "\n",
    "appx_time, appx_state = approximate_ds(2, 64, ref_state[t_idx:], ref_dstate[t_idx:], sim_time,\n",
    "                                       radius=1, dt=dt, input_fn=input_fn,\n",
    "                                       neuron_type=nengo.LIF(), max_rates=nengo.dists.Uniform(100, 200))\n",
    "plot_vdp(ref_time, ref_state, appx_time, appx_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Use these in your simulation\n",
    "T = 20.  # duration of simulation\n",
    "stim = piecewise({0.:[1., 0.], 1.:[0., 0.]})  # Use this as the input function to your network\n",
    "mu = 1.5  # damping coefficient\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "tau_syn = .1  # synaptic time constant \n",
    "N = 400       # number of neurons\n",
    "\n",
    "def vanderpol(x, mu):\n",
    "    ret = np.array(\n",
    "        [x[1], \n",
    "         mu*(1.-x[0]**2)*x[1]-x[0]])\n",
    "    return ret\n",
    "\n",
    "def decode(x, nonlin_fun, *nonlin_args):\n",
    "    return tau_syn*nonlin_fun(x, *nonlin_args) + x\n",
    "\n",
    "net = nengo.Network()\n",
    "with net:\n",
    "    stim = nengo.Node(stim)\n",
    "    ens = nengo.Ensemble(N, 2, radius=3.)\n",
    "    nengo.Connection(stim, ens, transform=tau_syn, synapse=tau_syn)\n",
    "    nengo.Connection(ens, ens, function=lambda x:decode(x, vanderpol, mu), synapse=tau_syn)\n",
    "    \n",
    "    probe_ens = nengo.Probe(ens, synapse=.01)\n",
    "sim = nengo.Simulator(net)\n",
    "sim.run(T, progress_bar=False)\n",
    "\n",
    "spiking_state = sim.data[probe_ens]\n",
    "ens.neuron_type = nengo.Direct()\n",
    "sim = nengo.Simulator(net)\n",
    "sim.run(T, progress_bar=False)\n",
    "reference_state = sim.data[probe_ens]\n",
    "\n",
    "t = sim.trange()\n",
    "\n",
    "plt.plot(sim.trange(), spiking_state[:, 0], 'r-', label=r'spiking $x_0$')\n",
    "plt.plot(sim.trange(), spiking_state[:, 1], 'b-', label=r'spiking $x_1$')\n",
    "plt.plot(sim.trange(), reference_state[:, 0], 'r--', label=r'direct $x_0$')\n",
    "plt.plot(sim.trange(), reference_state[:, 1], 'b--', label=r'direct $x_1$')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1., 1.))\n",
    "plt.xlabel(r'$t$')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(spiking_state[:, 0], spiking_state[:, 1], 'b', label='spiking mode')\n",
    "plt.plot(reference_state[:, 0], reference_state[:, 1], 'r', label='direct mode')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1., 1.));\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a canonical, nonlinear, chaotic dynamical system: the Lorenz \"butterfly\" attractor.  The equations are:\n",
    "        \n",
    "$$\n",
    "\\dot{x}_0 = \\sigma(x_1 - x_0) \\\\\\\n",
    "\\dot{x}_1 = x_0 (\\rho - x_2) - x_1  \\\\\\\n",
    "\\dot{x}_2 = x_0 x_1 - \\beta x_2 \n",
    "$$\n",
    "\n",
    "Since $x_2$ is centered around approximately $\\rho$, and since NEF ensembles are usually optimized to represent values within a certain radius of the origin, we substitute $x_2' = x_2 - \\rho$, giving these equations:\n",
    "$$\n",
    "\\dot{x}_0 = \\sigma(x_1 - x_0) \\\\\\\n",
    "\\dot{x}_1 = - x_0 x_2' - x_1\\\\\\\n",
    "\\dot{x}_2' = x_0 x_1 - \\beta (x_2' + \\rho) - \\rho\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8,
     21
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def test_lorenz():\n",
    "    # generate Lorenz dynamical system data\n",
    "    dt = 0.0001\n",
    "    sim_time = 5\n",
    "    \n",
    "    radius = 20\n",
    "    \n",
    "    sigma = 10\n",
    "    beta = 8.0 / 3\n",
    "    rho = 28\n",
    "\n",
    "    def lorentz(x):\n",
    "        dx0 = -sigma * x[0] + sigma * x[1]\n",
    "        dx1 = -x[0] * x[2] - x[1]\n",
    "        dx2 = x[0] * x[1] - beta * (x[2] + rho) - rho\n",
    "        return [dx0, dx1, dx2]\n",
    "\n",
    "    dsp = DSProcessor(lorentz, dim=3, seed=0, radius=radius, neuron_type=nengo.LIFRate())\n",
    "    ref_time, ref_state, ref_dstate = dsp.generate_data(sim_time, dt=dt)\n",
    "\n",
    "    appx_time, appx_state = approximate_ds(3, 1000, ref_state, ref_dstate, sim_time, radius=1, dt=dt)\n",
    "    diff_state = ref_state - appx_state[:-1]\n",
    "\n",
    "    # plot Lorentz Attractor data\n",
    "    def plot_lorenz(max_t):\n",
    "        idx = np.searchsorted(ref_time, max_t)\n",
    "        all_xstate = [ref_state[:, 0], appx_state[:-1, 0], diff_state[:, 0]]\n",
    "        all_ystate = [ref_state[:, 1], appx_state[:-1, 1], diff_state[:, 1]]\n",
    "        all_zstate = [ref_state[:, 2], appx_state[:-1, 2], diff_state[:, 2]]\n",
    "        xlims = (np.min(all_xstate), np.max(all_xstate))\n",
    "        ylims = (np.min(all_ystate), np.max(all_ystate))\n",
    "        zlims = (np.min(all_zstate), np.max(all_zstate))\n",
    "        fig_3d = plt.figure(figsize=(14, 4))\n",
    "        axs_3d = [fig_3d.add_subplot(1, 3, ax_idx+1, projection='3d') for ax_idx in range(3)]\n",
    "        axs_3d[0].plot(*ref_state[:idx].T)\n",
    "        axs_3d[1].plot(*appx_state[:idx].T)\n",
    "        axs_3d[2].plot(*diff_state[:idx].T)\n",
    "        axs_3d[0].set_title(\"ground truth\")\n",
    "        axs_3d[1].set_title(\"fit\")\n",
    "        axs_3d[2].set_title(\"difference\")\n",
    "        for ax in axs_3d:\n",
    "            ax.set_xlim(xlims)\n",
    "            ax.set_ylim(ylims)\n",
    "            ax.set_zlim(zlims)\n",
    "\n",
    "        fig_ts, axs_ts = plt.subplots(ncols=3, sharey=True, figsize=(14, 4))\n",
    "        axs_ts[0].plot(ref_time[:idx], ref_state[:idx])\n",
    "        axs_ts[1].plot(appx_time[:idx], appx_state[:idx])\n",
    "        axs_ts[2].plot(ref_time[:idx], diff_state[:idx])\n",
    "    plot_lorenz(1)\n",
    "    plot_lorenz(20)\n",
    "test_lorenz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8,
     21
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def test_lorenz():\n",
    "    # generate Lorenz dynamical system data\n",
    "    dt = 0.0001\n",
    "    sim_time = 10\n",
    "    sigma = 10\n",
    "    beta = 8.0 / 3\n",
    "    rho = 28\n",
    "\n",
    "    def lorentz(x):\n",
    "        dx0 = -sigma * x[0] + sigma * x[1]\n",
    "        dx1 = -x[0] * x[2] - x[1]\n",
    "        dx2 = x[0] * x[1] - beta * (x[2] + rho) - rho\n",
    "        return [dx0, dx1, dx2]\n",
    "\n",
    "    dsp = DSProcessor(lorentz, dim=3, seed=0)\n",
    "    ref_time, ref_state, ref_dstate = dsp.generate_data(sim_time, dt=dt)\n",
    "\n",
    "    appx_time, appx_state = approximate_ds(3, 1000, ref_state, ref_dstate, sim_time, dt=dt)\n",
    "    diff_state = ref_state - appx_state[:-1]\n",
    "\n",
    "    # plot Lorentz Attractor data\n",
    "    def plot_lorenz(max_t):\n",
    "        idx = np.searchsorted(ref_time, max_t)\n",
    "        all_xstate = [ref_state[:, 0], appx_state[:-1, 0], diff_state[:, 0]]\n",
    "        all_ystate = [ref_state[:, 1], appx_state[:-1, 1], diff_state[:, 1]]\n",
    "        all_zstate = [ref_state[:, 2], appx_state[:-1, 2], diff_state[:, 2]]\n",
    "        xlims = (np.min(all_xstate), np.max(all_xstate))\n",
    "        ylims = (np.min(all_ystate), np.max(all_ystate))\n",
    "        zlims = (np.min(all_zstate), np.max(all_zstate))\n",
    "        fig_3d = plt.figure(figsize=(14, 4))\n",
    "        axs_3d = [fig_3d.add_subplot(1, 3, ax_idx+1, projection='3d') for ax_idx in range(3)]\n",
    "        axs_3d[0].plot(*ref_state[:idx].T)\n",
    "        axs_3d[1].plot(*appx_state[:idx].T)\n",
    "        axs_3d[2].plot(*diff_state[:idx].T)\n",
    "        axs_3d[0].set_title(\"ground truth\")\n",
    "        axs_3d[1].set_title(\"fit\")\n",
    "        axs_3d[2].set_title(\"difference\")\n",
    "        for ax in axs_3d:\n",
    "            ax.set_xlim(xlims)\n",
    "            ax.set_ylim(ylims)\n",
    "            ax.set_zlim(zlims)\n",
    "\n",
    "        fig_ts, axs_ts = plt.subplots(ncols=3, sharey=True, figsize=(14, 4))\n",
    "        axs_ts[0].plot(ref_time[:idx], ref_state[:idx])\n",
    "        axs_ts[1].plot(appx_time[:idx], appx_state[:idx])\n",
    "        axs_ts[2].plot(ref_time[:idx], diff_state[:idx])\n",
    "    plot_lorenz(1)\n",
    "    plot_lorenz(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "# Factors that affect dynamics fit quality\n",
    "\n",
    "- Noise: in measurements and observations\n",
    "- Lag\n",
    "- Mismatch between data dimensionality and model capacity (model dimensions)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
