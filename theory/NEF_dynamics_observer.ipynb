{
 "metadata": {
  "name": "",
  "signature": "sha256:5c6830b06fd307cb9cb4c9deca3ee97f7656fb91f11970315ced2e75f775c1b3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Notebook description"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NEF specifies [how](http://nbviewer.ipython.org/github/fragapanagos/notebooks/blob/master/theory/NEF_dynamics.ipynb#How-to-find-weights-that-map-a-dynamical-system-onto-a-recurrent-neural-system) to map dynamical systems on to recurrent neural networks. However, using hardware imposes restrictions on what we can and cannot observe. Namely, we can only observe spikes from the hardware and cannot observe dendritic currents. This notebook outlines a method for observing state space values with the desired dynamics while subject to the hardware's constraints."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Summary of results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instead of sending spikes representing $x(t)$ to your observer, send the spikes representing $A'x(t)+B'u(t)=h_{syn}^{-1}(t)*x(t)$ to your observer.\n",
      "\n",
      "Match the observer time constant to the synaptic time constant."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "NEF recurrent neural system analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the NEF, a recurrent neural network is modeled with\n",
      "\n",
      "![NEF neural system](figures/neural_system.png \"NEF neural system\")\n",
      "\n",
      "where\n",
      " - $u(t)$ is the system input\n",
      " - $x(t)$ is the system state\n",
      "\n",
      "Solving for $X(s)$,\n",
      "\n",
      "\\begin{align}\n",
      "X(s) &= H(s)[A'X(s)+B'U(s)] \\\\\n",
      "(1-H(s)A')X(s) &= H(s)B'U(s) \\\\\n",
      "X(s) &= \\frac{H(s)B'}{1-H(s)A'}U(s) \\\\\n",
      " &= \\frac{B'}{1/H(s)-A'}U(s) \\\\\n",
      " &= \\frac{B'}{\\tau s+1-A'}U(s) \\\\\n",
      " &= \\frac{B'/(1-A')}{(\\tau/(1-A'))s+1}U(s) \\\\\n",
      "\\end{align}\n",
      "\n",
      "We use $A'$ and $B'$ to implement any linear dynamical system.\n",
      "\n",
      "Although standard nengo is consistent with this formulation, there are key differences between this formulation and our hardware implementation. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Standard nengo is consistent with NEF recurrent neural system"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we expand the standard nengo implementation and note whether each link is sending spikes or state space values.\n",
      "\n",
      "![standard nengo implementation](figures/neural_system_nengo_expanded.png \"standard nengo implementation\")\n",
      "\n",
      "where 'target' could be either the next Ensemble's somas or a Node/Probe. This figure has a few simplifications. First, I only show one neuron in the recurrent loop instead of an Ensemble of neurons. Second, I leave out the encoders/decoders. These first two simplifications are valid because we pick decoders that combine activity from the neurons so that the Ensemble's output is linear. Third, I assume that the target is using the same synaptic time constant as the recurrent connection.\n",
      "\n",
      "The nengo implementation is consistent with the NEF dynamical neural system formulation because the synaptic filtering is applied immediately to the output spikes of the neurons before transmitting to neurons' targets. Neurons do not send spikes to other neurons but rather send state space values. Because the state space values $x(t)$ and $u(t)$ are defined after the synapse and before the soma, we can say that they are represented by the set of currents in the dendrites of an Ensemble's neurons."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Hardware implementation is inconsistent with the NEF recurrent neural system"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Expanding the hardware implementation and and noting its data types, \n",
      "\n",
      "![hardware implementation](figures/neural_system_spiking_expanded.png \"hardware implementation\")\n",
      "\n",
      "Here, we represent $x(t)$ and $u(t)$ with spikes instead of the currents in a population's dendrites. As a consequence, to pass $x(t)$ to the target, which could be a soma or Node/Probe as before, we filter the spikes that represent $x(t)$. That is, we effectively implement\n",
      "\n",
      "![neural system with observer](figures/neural_system_output_synapse.png \"neural system with observer\")\n",
      "\n",
      "where $h_{obs}(t)$ is our observer that converts spikes into state space values and $y(t)$ is our observation that could either be passed to another soma or read out. To be consistent with the NEF recurrent neural system formulation, we would like $y(t)=x(t)$, but the observed output dynamics are the system dynamics further filtered by the observer."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " That is,\n",
      "\n",
      "\\begin{align}\n",
      "Y(s) &= H_{obs}(s)X(s) \\\\\n",
      " &= H_{obs}(s)\\frac{B'/(1-A')}{(\\tau/(1-A'))s+1}U(s) \\\\\n",
      " &= \\frac{1}{\\tau_{obs}s+1}\\frac{B'/(1-A')}{(\\tau/(1-A'))s+1}U(s) \\\\\n",
      "\\end{align}\n",
      "\n",
      "which we recognize as a second order low pass filtered version of $U(s)$ because the denominator will be a second order polynomial of $s$.\n",
      "\n",
      "The NEF book (at the end of section 8.1.3 Revisiting levels of analysis,) recognizes an equivalent issue where there is both a \"decoding\" synapse and an \"encoding\" synapse between layers of somas but brushes the issue aside. Unfortunately, for applications such as robot control where timing and precision are critical, we cannot ignore this issue (at least until we develop robot controllers that are robust to delays). Another use case is when we want to observe the system using a long synaptic time constant to reduce noise but not pay the cost of extra latency."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Reposition the observer to cancel its effect"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a number of ways to cancel the effect of the observer (see [Appendix](#Solving-for-system-state-variables)). One intuitive idea is to put it in parallel with the synaptic dynamics.\n",
      "\n",
      "![observer parallels synapse](figures/neural_system_parallel_observer.png \"observer parallels synapse\")\n",
      "\n",
      "The reasoning of this solution is that if we tap the signal before the synapse and feed it through a system identical to the synapse, we will have $y(t)=x(t)$. This is also nice for the hardware because $e(t)$ are exactly the spikes sent to the synapses of the neurons. $e(t)=A'x(t)+B'u(t)=h_{syn}^{-1}(t)*x(t)$. To contrast, in the previous system, we would send the spike representing $x(t)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Continuing,\n",
      "\n",
      "\\begin{align}\n",
      "E(S) &= A'H_{syn}(s)E(s)+B'U(s) \\\\\n",
      " &= \\frac{B'}{1-A'H_{syn}(s)}U(s) \\\\\n",
      " &= \\frac{B/H_{syn}(s)}{1/H_{syn}(s)-A}U(s) \\\\\n",
      "\\end{align}\n",
      "\n",
      "so\n",
      "\n",
      "\\begin{align}\n",
      "Y(s) &= H_{obs}(s)X(s) \\\\\n",
      " &= H_{obs}(s)\\frac{B/H_{syn}(s)}{1/H_{syn}(s)-A}U(s) \\\\\n",
      "\\end{align}\n",
      "\n",
      "where we now see the opportunity to cancel $H_{obs}(s)$ with the $1/H_{syn}(s)$ in the numerator by setting $\\tau_{syn}=\\tau_{obs}$ so that $H_{obs}(s)=H_{syn}(s)$. Doing so,\n",
      "\n",
      "\\begin{align}\n",
      "Y(s) &= \\frac{B}{1/H_{syn}(s)-A}U(s) \\\\\n",
      " &= X(s) \\\\\n",
      "\\end{align}\n",
      "\n",
      "as we intend."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Applying this to the hardware implementation, we would configure our network as\n",
      "\n",
      "![hardware implementation consistent with NEF neural system formulation](figures/neural_system_spikes_parallel_expanded.png \"hardware implementation consistent with NEF neural system formulation\")\n",
      "\n",
      "where now the target sees the same dynamics as the soma in the recurrent loop."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Simulations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# demonstration of NEF dynamics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# demonstration of NEF dynamics passed through observer synapse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# demonstration of alternative formulation that accounts for dynamics of the observer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Appendix"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Solving for system state variables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are two linear system configurations that differ in their relative placement of $h(t)$ and $A$ in the feedback loop. It's interesting to note their similarities and differences. On the left, $h(t)$ is in the feedfoward path and $A$ is in the feedback loop. On the right, $h(t)$ is in the feedback path and $A$ is in the feedfoward path."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "<table>\n",
      "    <tr>\n",
      "        <td>![feedfoward h, feedback A](figures/system_h_a.png \"feedfoward h, feedback A\")</td>\n",
      "        <td>![feedfoward A, feedback h](figures/system_a_h.png \"feedfoward A, feedback h\")</td>\n",
      "    </tr>\n",
      "        <td>\n",
      "            \\begin{align}\n",
      "            X(s) &= H(s)(AX(s)+BU(s)) \\\\\n",
      "             &= \\frac{BH(s)}{1-AH(s)}U(s) \\\\\n",
      "            X(s) &= \\frac{B}{1/H(s)-A}U(s) \\\\\n",
      "            \\\\\n",
      "            Z(s) &= AH(s)(Z(s)+BU(s)) \\\\\n",
      "             &= \\frac{ABH(s)}{1-AH(s)}U(s) \\\\\n",
      "            Z(s &= \\frac{AB}{1/H(s)-A}U(s) \\\\\n",
      "            \\\\\n",
      "            E(s) &= AH(s)E(s)+BU(s) \\\\\n",
      "             &= \\frac{B}{1-AH(s)}U(s) \\\\\n",
      "            E(s) &= \\frac{B/H(s)}{1/H(s)-A}U(s) \\\\\n",
      "            \\end{align}\n",
      "        </td>\n",
      "        <td>\n",
      "            \\begin{align}\n",
      "            X(s) &= A(H(s)X(s)+BU(s)) \\\\\n",
      "             &= \\frac{AB}{1-AH(s)}U(s) \\\\\n",
      "            X(s) &= \\frac{AB/H(s)}{1/H(s)-A}U(s) \\\\\n",
      "            \\\\\n",
      "            Z(s) &= AH(s)(Z(s)+BU(s)) \\\\\n",
      "             &= \\frac{ABH(s)}{1-AH(s)}U(s) \\\\\n",
      "            Z(s) &= \\frac{AB}{1/H(s)-A}U(s) \\\\\n",
      "            \\\\\n",
      "            E(s) &= AH(s)E(s)+BU(s) \\\\\n",
      "             &= \\frac{B}{1-AH(s)}U(s) \\\\\n",
      "            E(s) &= \\frac{B/H(s)}{1/H(s)-A}U(s) \\\\\n",
      "            \\end{align}\n",
      "        </td>\n",
      "    </tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The difference in configurations only produces a difference in the $X(s)$ state.\n",
      "\n",
      "If we were to tap a state through an observer synapse, tapping $E(s)$ of either system or $X(s)$ of the system on the right would be good candidates. Because these state variables have $1/H(s)$ in their numerators, they could cancel the effect of the observer synapse and have the output be a first order system with respect to the input $U(s)$."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}