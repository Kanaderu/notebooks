{
 "metadata": {
  "name": "",
  "signature": "sha256:fc5795d28260381b906b8fe044b3fa7e95300c2dc89411a7d533f4e56328a9e7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Notebook description"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook examines our ability to approximate arbitrary functions linearly. \n",
      "\n",
      "In linear function approximation, our goal is to approximate a desired function, $\\mathbf{y}$, as the linear combination of approximator functions, $\\mathbf{a}_i$, using weights $\\mathbf{x}$. That is, \n",
      "\n",
      "$$\n",
      "\\mathbf{y}\\approx\\mathbf{A}\\mathbf{x}\n",
      "$$\n",
      "\n",
      "Specifically, we would like to know: Given a regressand and set of regressors, how well could our regressors approximate the regressand?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Summary of results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "...punchline goes here..."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Notation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The desired function is described with $m$ sample points and could be a single-dimensional or multi-dimensional function. In the single dimensional case,\n",
      "\n",
      "$$\n",
      "\\begin{bmatrix}\n",
      "y_0 \\\\\n",
      "y_1 \\\\\n",
      "\\vdots \\\\\n",
      "y_m \\\\\n",
      "\\end{bmatrix}\n",
      "\\approx\n",
      "\\begin{bmatrix}\n",
      "A_{0,0} & A_{0,1} & \\cdots & A_{0,n} \\\\\n",
      "A_{1,0} & A_{1,1} & \\cdots & A_{1,n} \\\\\n",
      "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
      "A_{m,0} & A_{m,1} & \\cdots & A_{m,n} \\\\\n",
      "\\end{bmatrix}\n",
      "\\begin{bmatrix}\n",
      "x_0 \\\\\n",
      "x_1 \\\\\n",
      "\\vdots \\\\\n",
      "x_n \\\\\n",
      "\\end{bmatrix}\n",
      "$$\n",
      "\n",
      "Or put another way,\n",
      "\n",
      "$$\n",
      "\\begin{bmatrix}\n",
      "| \\\\\n",
      "\\mathbf{y} \\\\\n",
      "| \\\\\n",
      "\\end{bmatrix}\n",
      "\\approx\n",
      "\\begin{bmatrix}\n",
      "| & | &  & | \\\\\n",
      "\\mathbf{a}_0 & \\mathbf{a}_1 & \\cdots & \\mathbf{a}_n \\\\\n",
      "| & | &  & | \n",
      "\\end{bmatrix}\n",
      "\\begin{bmatrix}\n",
      "| \\\\\n",
      "\\mathbf{x} \\\\\n",
      "| \\\\\n",
      "\\end{bmatrix}\n",
      "$$\n",
      "\n",
      "In the multidimensional case,\n",
      "\n",
      "$$\n",
      "\\begin{bmatrix}\n",
      "| & | & & | \\\\\n",
      "\\mathbf{y}_0 & \\mathbf{y}_1 & \\cdots & \\mathbf{y}_d \\\\\n",
      "| & | & & | \\\\\n",
      "\\end{bmatrix}\n",
      "\\approx\n",
      "\\begin{bmatrix}\n",
      "| & | &  & | \\\\\n",
      "\\mathbf{a}_0 & \\mathbf{a}_1 & \\cdots & \\mathbf{a}_n \\\\\n",
      "| & | &  & | \n",
      "\\end{bmatrix}\n",
      "\\begin{bmatrix}\n",
      "| & | & & | \\\\\n",
      "\\mathbf{x}_0 & \\mathbf{x}_1 & \\cdots & \\mathbf{x}_d \\\\\n",
      "| & | & & | \\\\\n",
      "\\end{bmatrix}\n",
      "$$\n",
      "\n",
      "so in general, $\\mathbf{y}\\in\\mathbb{R}^{m\\times d}$, $\\mathbf{A}\\in\\mathbb{R}^{m\\times n}$, and $\\mathbf{x}\\in\\mathbb{R}^{n\\times d}$. \n",
      "\n",
      "However the multidimensional case is [separable](#Separability-of-decoding-dimensions), so we need only analyze the single dimensional case where $\\mathbf{y}\\in\\mathbb{R}^{m}$, $\\mathbf{A}\\in\\mathbb{R}^{m\\times n}$, and $\\mathbf{x}\\in\\mathbb{R}^{n}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As an aside, in statistics, $\\mathbf{y}$ is called the regressand, $\\mathbf{a}_i$ are called regressors, and $\\mathbf{x}$ are the regression coefficients."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Background"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our analysis will centers on the properties of $\\mathbf{A}$ in relation to the operation $\\mathbf{A}\\mathbf{x}$, which is a linear map $L:\\mathbb{R}^n\\rightarrow\\mathbb{R}^m$ between two vector spaces $\\mathbb{R}^n$ and $\\mathbb{R}^m$ where $\\mathbf{x}\\in\\mathbb{R}^n$ and $\\mathbf{y}\\in\\mathbb{R}^m$.\n",
      "\n",
      "The set of vectors $\\mathbf{y}\\in\\mathbb{R}^m$ such that $\\mathbf{y}=\\mathbf{A}\\mathbf{x}$ for any $\\mathbf{x}\\in\\mathbb{R}^n$ is called the _column space_ of $\\mathbf{A}$. The dimensionality of the column space is the _rank_ of $\\mathbf{A}$.\n",
      "\n",
      "The set of vectors $\\mathbf{x}\\in\\mathbb{R}^n$ such that $\\mathbf{A}^T\\mathbf{y}=\\mathbf{x}$ for any $\\mathbf{y}\\in\\mathbb{R}^m$ is called the _row space_ of $\\mathbf{A}$. The dimensionality of the row space is the also the rank of $\\mathbf{A}$.\n",
      "\n",
      "The set of vectors $\\mathbf{x}\\in\\mathbb{R}^n$ such that $\\mathbf{0}=\\mathbf{A}\\mathbf{x}$ is called the _null_ space. The dimensionality of the null space is the _corank_ of $\\mathbf{A}$.\n",
      "\n",
      "The set of vectors $\\mathbf{y}\\in\\mathbb{R}^m$ such that $\\mathbf{A}^T\\mathbf{y}=0$ is called the _left nullspace_. The left null space is the complement of the column space and its dimensionality is also the corank of $\\mathbf{A}$.\n",
      "\n",
      "$\\mathbf{A}$ can be decomposed via SVD as\n",
      "\n",
      "$$\n",
      "\\mathbf{A} = \\mathbf{U}\\Sigma\\mathbf{V}^T\n",
      "$$\n",
      "\n",
      "where\n",
      " - the columns of $\\mathbf{V}$ form an orthogonal basis for $\\mathbb{R}^n$,\n",
      " - the columns of $\\mathbf{U}$ form an orthogonal basis for $\\mathbb{R}^m$,\n",
      " - $\\Sigma$ is diagonal and the number of nonzero entries of $\\Sigma$ is the rank of $\\mathbf{A}$, \n",
      "\n",
      "therefore\n",
      " - the columns of $\\mathbf{V}$ corresponding to the zero entries of $\\Sigma$ form an orthogonal basis for the null space of $\\mathbf{A}$,\n",
      " - the columns of $\\mathbf{U}$ corresponding to the zero entries of $\\Sigma$ form an orthogonal basis for the left null space of $\\mathbf{A}$."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the SVD, we can determine exactly how much error we can expect when approximating a function described by $\\mathbf{y}$ using $\\mathbf{A}\\mathbf{x}$. The error in our approximation will be exactly captured in the left null space of $\\mathbf{A}$.\n",
      "\n",
      "\\begin{align}\n",
      "E &= \\mathbf{y}-\\mathbf{A}\\mathbf{x} \\\\\n",
      " &= \\mathbf{y}-\\mathbf{U}\\Sigma\\mathbf{V}^T\\mathbf{x} \\\\\n",
      " &= \\mathbf{U}^T\\mathbf{y}-\\mathbf{U}^T\\mathbf{U}\\Sigma\\mathbf{V}^T\\mathbf{x} \\\\\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Appendix"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Separability of decoding dimensions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With no other constraints on $\\mathbf{x}$,\n",
      "$$\n",
      "\\begin{bmatrix}\n",
      "| & | & & | \\\\\n",
      "\\mathbf{y}_0 & \\mathbf{y}_1 & \\cdots & \\mathbf{y}_d \\\\\n",
      "| & | & & | \\\\\n",
      "\\end{bmatrix}\n",
      "=\n",
      "\\begin{bmatrix}\n",
      "| & | &  & | \\\\\n",
      "\\mathbf{a}_0 & \\mathbf{a}_1 & \\cdots & \\mathbf{a}_n \\\\\n",
      "| & | &  & | \n",
      "\\end{bmatrix}\n",
      "\\begin{bmatrix}\n",
      "| & | & & | \\\\\n",
      "\\mathbf{x}_0 & \\mathbf{x}_1 & \\cdots & \\mathbf{x}_d \\\\\n",
      "| & | & & | \\\\\n",
      "\\end{bmatrix}\n",
      "$$\n",
      "\n",
      "can be separated into\n",
      "\\begin{align}\n",
      "\\begin{bmatrix}\n",
      "    | \\\\\n",
      "    \\mathbf{y}_0 \\\\\n",
      "    | \\\\\n",
      "\\end{bmatrix}\n",
      "&=\n",
      "\\begin{bmatrix}\n",
      "    | & | &  & | \\\\\n",
      "    \\mathbf{a}_0 & \\mathbf{a}_1 & \\cdots & \\mathbf{a}_n \\\\\n",
      "    | & | &  & | \n",
      "\\end{bmatrix}\n",
      "\\begin{bmatrix}\n",
      "    | \\\\\n",
      "    \\mathbf{x}_0 \\\\\n",
      "    | \\\\\n",
      "\\end{bmatrix} \\\\ \\\\\n",
      "\\begin{bmatrix}\n",
      "    | \\\\\n",
      "    \\mathbf{y}_1 \\\\\n",
      "    | \\\\\n",
      "\\end{bmatrix}\n",
      "&=\n",
      "\\begin{bmatrix}\n",
      "    | & | &  & | \\\\\n",
      "    \\mathbf{a}_0 & \\mathbf{a}_1 & \\cdots & \\mathbf{a}_n \\\\\n",
      "    | & | &  & | \n",
      "\\end{bmatrix}\n",
      "\\begin{bmatrix}\n",
      "    | \\\\\n",
      "    \\mathbf{x}_1 \\\\\n",
      "    | \\\\\n",
      "\\end{bmatrix} \\\\\n",
      "&\\ \\vdots \\\\\n",
      "\\begin{bmatrix}\n",
      "    | \\\\\n",
      "    \\mathbf{y}_d \\\\\n",
      "    | \\\\\n",
      "\\end{bmatrix}\n",
      "&=\n",
      "\\begin{bmatrix}\n",
      "    | & | &  & | \\\\\n",
      "    \\mathbf{a}_0 & \\mathbf{a}_1 & \\cdots & \\mathbf{a}_n \\\\\n",
      "    | & | &  & | \n",
      "\\end{bmatrix}\n",
      "\\begin{bmatrix}\n",
      "    | \\\\\n",
      "    \\mathbf{x}_d \\\\\n",
      "    | \\\\\n",
      "\\end{bmatrix} \\\\ \\\\\n",
      "\\end{align}\n",
      "\n",
      "where we can consider each equation separately.\n",
      "\n",
      "Note that there are times when we do impose constraints on $\\mathbf{x}$. For example, when using the generalized form of least squares to find $\\mathbf{x}$, we seek\n",
      "\n",
      "$\\DeclareMathOperator*{\\argmin}{arg\\,min}$\n",
      "$$\n",
      "\\argmin_x \\|\\mathbf{A}\\mathbf{x}-\\mathbf{y}\\|_2^2+\\|\\mathbf{\\Gamma}\\mathbf{x}\\|_2^2\n",
      "$$\n",
      "\n",
      "Here, $\\mathbf{\\Gamma}$ could impose a relationship between the columns of $\\mathbf{x}$."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}